{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonali-debnath/musical-BCI/blob/main/FMRI_PROTOTYPICAL_MAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING THE DATASET**"
      ],
      "metadata": {
        "id": "OEOKgpD-xEri"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtfdE0beoYVK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['rocknroll', 'symphonic', 'rocknroll', 'metal', 'symphonic', 'country', 'country', 'ambient',\n",
        "              'ambient', 'country', 'symphonic', 'symphonic', 'ambient', 'metal', 'metal', 'ambient',\n",
        "              'rocknroll', 'country', 'rocknroll', 'ambient', 'symphonic', 'metal', 'country', 'metal',\n",
        "              'rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "output_folder = 'output_images7'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Create a subfolder for \"no music\"\n",
        "no_music_folder = os.path.join(output_folder, 'no_music')\n",
        "os.makedirs(no_music_folder, exist_ok=True)\n",
        "\n",
        "# Save images for \"no music\" condition (before music starts)\n",
        "for i in range(25):\n",
        "    plt.imshow(nifti_data[:, :, i, 0], cmap='gray')  # Assuming you want slices from the first time point\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Save the image to the \"no music\" folder with a unique name\n",
        "    image_filename = f\"{no_music_folder}/no_music_slice_{i}.png\"\n",
        "    plt.savefig(image_filename, bbox_inches='tight', pad_inches=0.0)\n",
        "    plt.clf()  # Clear the figure for the next iteration\n",
        "\n",
        "# Iterate over the dataframe and save images for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to slice number based on your logic\n",
        "    slice_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[2] - 26))\n",
        "\n",
        "    # Ensure that slice_start is within bounds\n",
        "    slice_start = max(0, min(slice_start, nifti_data.shape[2] - 26))\n",
        "\n",
        "    # Create a subfolder for each genre\n",
        "    genre_folder = os.path.join(output_folder, genre)\n",
        "    os.makedirs(genre_folder, exist_ok=True)\n",
        "\n",
        "    # Create a subplot for each slice\n",
        "    for i in range(slice_start, slice_start + 25):\n",
        "        plt.imshow(nifti_data[:, :, i, 0], cmap='gray')  # Assuming you want slices from the first time point\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Save the image to the genre-specific folder with a unique name\n",
        "        image_filename = f\"{genre_folder}/{genre}_slice_{i}.png\"\n",
        "        plt.savefig(image_filename, bbox_inches='tight', pad_inches=0.0)\n",
        "        plt.clf()  # Clear the figure for the next iteration\n",
        "\n",
        "print(f\"All images saved to {output_folder}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEGMENTATION**"
      ],
      "metadata": {
        "id": "-7uP3cygu_1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Function to perform image segmentation\n",
        "def perform_segmentation(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply a simple thresholding for segmentation\n",
        "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return binary_image\n",
        "\n",
        "# Function to overlay segmented spots on the original image\n",
        "def overlay_spots(original_image, segmented_image):\n",
        "    # Convert original image to BGR for color overlay\n",
        "    original_image_bgr = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Set the spots in the original image to red\n",
        "    original_image_bgr[segmented_image > 0] = [255, 0, 0]  # Red color\n",
        "\n",
        "    return original_image_bgr\n",
        "\n",
        "# Path to the output folder containing genre-specific subfolders\n",
        "output_folder = 'output_images7'\n",
        "\n",
        "# Get a list of genre folders\n",
        "genre_folders = [f for f in os.listdir(output_folder) if os.path.isdir(os.path.join(output_folder, f))]\n",
        "\n",
        "# Iterate over each genre folder, perform segmentation, overlay spots, and display the results\n",
        "for genre in genre_folders:\n",
        "    # Get the path to one image in the genre folder\n",
        "    genre_folder = os.path.join(output_folder, genre)\n",
        "    image_files = [f for f in os.listdir(genre_folder) if f.endswith('.png')]\n",
        "\n",
        "    if image_files:\n",
        "        # Select the first image in the folder\n",
        "        image_path = os.path.join(genre_folder, image_files[0])\n",
        "\n",
        "        # Perform segmentation\n",
        "        segmented_image = perform_segmentation(image_path)\n",
        "\n",
        "        # Read the original image\n",
        "        original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Overlay spots on the original image\n",
        "        result_image = overlay_spots(original_image, segmented_image)\n",
        "\n",
        "        # Display the original and overlaid images\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(original_image, cmap='gray')\n",
        "        plt.title(f\"{genre} - Original\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(segmented_image, cmap='gray')\n",
        "        plt.title(f\"{genre} - Segmented\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(result_image)\n",
        "        plt.title(f\"{genre} - Active Area highlighted\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No images found in the folder for genre: {genre}\")\n"
      ],
      "metadata": {
        "id": "oHituN-EurlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "odzJvNetvIVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import time\n",
        "\n",
        "# Path to the folder containing genre-specific subfolders\n",
        "input_folder = 'output_images7'\n",
        "\n",
        "# Load images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Get a list of genre folders\n",
        "genre_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n",
        "\n",
        "for label, genre in enumerate(genre_folders):\n",
        "    genre_folder = os.path.join(input_folder, genre)\n",
        "    image_files = [f for f in os.listdir(genre_folder) if f.endswith('.png')]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(genre_folder, image_file)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (128, 128))  # Resize the images to a consistent size\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images) / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(genre_folders), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape input for CNN (add the channel dimension)\n",
        "X_train = X_train.reshape((-1, 128, 128, 1))\n",
        "X_test = X_test.reshape((-1, 128, 128, 1))\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test))\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "#Evaluate the model\n",
        "start_time = time.time()\n",
        "y_pred = model.predict(X_test)\n",
        "inference_time = time.time() - start_time\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
        "\n",
        "# Calculate sensitivity, specificity, F1 score\n",
        "if len(genre_folders) == 2:  # Binary classification\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    f1_score = 2 * tp / (2 * tp + fp + fn)\n",
        "else:  # Multi-class classification\n",
        "    sensitivity = recall_score(y_test, y_pred_labels, average='weighted')\n",
        "    specificity = \"Not applicable for multi-class\"\n",
        "    f1_score = f1_score(y_test, y_pred_labels, average='weighted')\n",
        "\n",
        "# Calculate AUC\n",
        "y_one_hot = keras.utils.to_categorical(y_test, num_classes=len(genre_folders))\n",
        "roc_auc = roc_auc_score(y_one_hot, y_pred, multi_class='ovr')\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nTest Accuracy: {accuracy}\")\n",
        "print(f\"Sensitivity: {sensitivity}\")\n",
        "print(f\"Specificity: {specificity}\")\n",
        "print(f\"F1 Score: {f1_score}\")\n",
        "print(f\"AUC: {roc_auc}\")\n",
        "print(f\"Training Time: {train_time} seconds\")\n",
        "print(f\"Inference Time per Sample: {inference_time / len(y_test)} seconds\")\n"
      ],
      "metadata": {
        "id": "ITVDT39Xurs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROTYPICAL MAML**"
      ],
      "metadata": {
        "id": "OG3iiiyZvaHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Initialize variables for metrics\n",
        "accuracy_list = []\n",
        "sensitivity_list = []\n",
        "specificity_list = []\n",
        "f1_score_list = []\n",
        "auc_list = []\n",
        "train_time_list = []\n",
        "inference_time_list = []\n",
        "confusion_matrices = []\n",
        "\n",
        "# Set your data directory\n",
        "train_data_dir = 'output_images7'  # Replace with the path to your train data\n",
        "\n",
        "# Set the number of classes\n",
        "num_classes = 6\n",
        "\n",
        "# Set other hyperparameters\n",
        "learning_rate = 0.003\n",
        "meta_step_size = 0.25\n",
        "inner_batch_size = 25\n",
        "eval_batch_size = 25\n",
        "meta_iters = 1\n",
        "inner_iters = 4\n",
        "eval_interval = 1\n",
        "img_height, img_width = 28, 28\n",
        "\n",
        "# Data generator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Prototypical Network architecture\n",
        "def conv_bn(x):\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return layers.ReLU()(x)\n",
        "\n",
        "def build_prototypical_net(input_shape, num_classes):\n",
        "    inputs = layers.Input(input_shape)\n",
        "    x = conv_bn(inputs)\n",
        "    x = conv_bn(x)\n",
        "    x = conv_bn(x)\n",
        "    x = conv_bn(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "# Instantiate the model\n",
        "model = build_prototypical_net((img_height, img_width, 3), num_classes)\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "optimizer = optimizers.SGD(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "training = []\n",
        "\n",
        "curr = time.time()\n",
        "\n",
        "for meta_iter in range(meta_iters):\n",
        "    frac_done = meta_iter / meta_iters\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    old_vars = model.get_weights()\n",
        "\n",
        "    # Sample a few images for testing from the training set\n",
        "    test_images, test_labels = next(train_generator)\n",
        "\n",
        "    mini_dataset = iter(train_generator)\n",
        "\n",
        "    for i in range(inner_iters):\n",
        "        images, labels = next(mini_dataset)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = model(images)\n",
        "            loss = tf.keras.losses.categorical_crossentropy(labels, preds)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "    new_vars = model.get_weights()\n",
        "\n",
        "    for var in range(len(new_vars)):\n",
        "        new_vars[var] = old_vars[var] + ((new_vars[var] - old_vars[var]) * cur_meta_step_size)\n",
        "\n",
        "    model.set_weights(new_vars)\n",
        "\n",
        "    if meta_iter % eval_interval == 0:\n",
        "        old_vars = model.get_weights()\n",
        "\n",
        "        for i in range(inner_iters):\n",
        "            with tf.GradientTape() as tape:\n",
        "                preds = model(test_images)\n",
        "                loss = tf.keras.losses.categorical_crossentropy(test_labels, preds)\n",
        "\n",
        "            grads = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        test_preds = model.predict(test_images)\n",
        "        test_preds = tf.argmax(test_preds, axis=1).numpy()\n",
        "        num_correct = (test_preds == tf.argmax(test_labels, axis=1).numpy()).sum()\n",
        "        model.set_weights(old_vars)\n",
        "        accuracy = num_correct / eval_batch_size\n",
        "        accuracy_list.append(accuracy)\n",
        "\n",
        "        # Calculate Confusion Matrix\n",
        "        cm = confusion_matrix(np.argmax(test_labels, axis=1), test_preds)\n",
        "        confusion_matrices.append(cm)\n",
        "\n",
        "        # Calculate Sensitivity, Specififcity, and F1 Score\n",
        "        tp = cm[1][1]\n",
        "        fp = cm[0][1]\n",
        "        fn = cm[1][0]\n",
        "        sensitivity = tp / (tp + fp)\n",
        "        specififcity = tp / (tp + fn)\n",
        "        f1_score = 2 * (sensitivity * specififcity) / (sensitivity + specififcity)\n",
        "\n",
        "        precision_list.append(sensitivity)\n",
        "        recall_list.append(specififcity)\n",
        "        f1_score_list.append(f1_score)\n",
        "\n",
        "stop = time.time()\n",
        "train_time_list.append(stop - curr)\n",
        "print(f'Final Test accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Final Time: {stop - curr}')\n",
        "\n",
        "# Calculate average metrics\n",
        "avg_accuracy = np.mean(accuracy_list)\n",
        "avg_sensitivity = np.mean(sensitivity_list)\n",
        "avg_specififcity = np.mean(specififcity_list)\n",
        "avg_f1_score = np.mean(f1_score_list)\n",
        "\n",
        "print(f\"\\nAverage Test Accuracy: {avg_accuracy}\")\n",
        "print(f\"Average Sensitivity: {avg_sensitivity}\")\n",
        "print(f\"Average Specififcity: {avg_specififcity}\")\n",
        "print(f\"Average F1 Score: {avg_f1_score}\")\n",
        "print(f\"Average Training Time: {np.mean(train_time_list)} seconds\")\n",
        "print(f\"Average Inference Time per Sample: {np.mean(inference_time_list)} seconds\")\n"
      ],
      "metadata": {
        "id": "n9_r945AurvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print correlation matrix\n",
        "avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
        "correlation_matrix = np.corrcoef(avg_confusion_matrix)\n",
        "\n",
        "print(\"\\nAverage Confusion Matrix:\")\n",
        "print(avg_confusion_matrix)\n",
        "\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(avg_confusion_matrix.astype(int), annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Visualize Correlation Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pykOv7Iayv-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BOLD SIGNALS**"
      ],
      "metadata": {
        "id": "0zFLNEeDvtL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Example data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['rocknroll', 'symphonic', 'rocknroll', 'metal', 'symphonic', 'country', 'country', 'ambient',\n",
        "              'ambient', 'country', 'symphonic', 'symphonic', 'ambient', 'metal', 'metal', 'ambient',\n",
        "              'rocknroll', 'country', 'rocknroll', 'ambient', 'symphonic', 'metal', 'country', 'metal',\n",
        "              'rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create a subfolder for BOLD signals\n",
        "output_folder = 'bold_signals'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Iterate over the dataframe and extract BOLD signals for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to volume number based on your logic\n",
        "    volume_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Ensure that volume_start is within bounds\n",
        "    volume_start = max(0, min(volume_start, nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Extract BOLD signals for each volume in the duration\n",
        "    bold_signals = nifti_data[:, :, :, volume_start:volume_start + 25].mean(axis=(0, 1, 2))\n",
        "\n",
        "    # Plot and save the BOLD signal\n",
        "    plt.plot(bold_signals, label=genre)\n",
        "    plt.xlabel('Time (Volumes)')\n",
        "    plt.ylabel('Mean BOLD Signal')\n",
        "    plt.title(f'BOLD Signal for {genre}')\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot to the output folder with a unique name\n",
        "    plot_filename = f\"{output_folder}/{genre}_bold_signal.png\"\n",
        "    plt.savefig(plot_filename, bbox_inches='tight', pad_inches=0.0)\n",
        "    plt.clf()  # Clear the figure for the next iteration\n",
        "\n",
        "print(f\"All BOLD signals plotted and saved to {output_folder}.\")\n"
      ],
      "metadata": {
        "id": "4Jzq3gNmurxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['Rocknroll', 'Symphonic', 'Rocknroll', 'Metal', 'Symphonic', 'Country', 'Country', 'Ambient',\n",
        "          'Ambient', 'Country', 'Symphonic', 'Symphonic', 'Ambient', 'Metal', 'Metal', 'Ambient',\n",
        "          'Rocknroll', 'Country', 'Rocknroll', 'Ambient', 'Symphonic', 'Metal', 'Country', 'Metal',\n",
        "          'Rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create an empty array to accumulate BOLD signals for each genre\n",
        "all_bold_signals = []\n",
        "\n",
        "# Iterate over the dataframe and extract BOLD signals for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to volume number based on your logic\n",
        "    volume_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Ensure that volume_start is within bounds\n",
        "    volume_start = max(0, min(volume_start, nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Extract BOLD signals for each volume in the duration\n",
        "    bold_signals = nifti_data[:, :, :, volume_start:volume_start + 25].mean(axis=(0, 1, 2))\n",
        "\n",
        "    # Accumulate the BOLD signals for each genre\n",
        "    all_bold_signals.append((genre, bold_signals))\n",
        "\n",
        "# Plot all BOLD signals in a single plot with different markers and line styles\n",
        "markers = ['o', 's', '^', 'D', '*', '2']\n",
        "line_styles = ['-', '-', '-', '-', '-', ':']\n",
        "for i, (genre, bold_signals) in enumerate(all_bold_signals):\n",
        "    plt.plot(bold_signals, label=genre, marker=markers[i % len(markers)], linestyle=line_styles[i % len(line_styles)])\n",
        "\n",
        "plt.xlabel('Time (Volumes) →')\n",
        "plt.ylabel('Mean BOLD Signal →')\n",
        "plt.title('BOLD Signals for Different Genres')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7aVGzzk5urzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['Rocknroll', 'Symphonic', 'Rocknroll', 'Metal', 'Symphonic', 'Country', 'Country', 'Ambient',\n",
        "          'Ambient', 'Country', 'Symphonic', 'Symphonic', 'Ambient', 'Metal', 'Metal', 'Ambient',\n",
        "          'Rocknroll', 'Country', 'Rocknroll', 'Ambient', 'Symphonic', 'Metal', 'Country', 'Metal',\n",
        "          'Rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create an empty array to accumulate BOLD signals for each genre\n",
        "all_bold_signals = []\n",
        "\n",
        "# Iterate over the dataframe and extract BOLD signals for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to volume number based on your logic\n",
        "    volume_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Ensure that volume_start is within bounds\n",
        "    volume_start = max(0, min(volume_start, nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Extract BOLD signals for each volume in the duration\n",
        "    bold_signals = nifti_data[:, :, :, volume_start:volume_start + 25].std(axis=(0, 1, 2))\n",
        "\n",
        "    # Accumulate the BOLD signals for each genre\n",
        "    all_bold_signals.append((genre, bold_signals))\n",
        "\n",
        "# Plot all BOLD signals in a single plot with different markers and line styles\n",
        "markers = ['o', 's', '^', 'D', '*', '2']\n",
        "line_styles = ['-', '-', '-', '-', '-', ':']\n",
        "for i, (genre, bold_signals) in enumerate(all_bold_signals):\n",
        "    plt.plot(bold_signals, label=genre, marker=markers[i % len(markers)], linestyle=line_styles[i % len(line_styles)])\n",
        "\n",
        "plt.xlabel('Time (Volumes) →')\n",
        "plt.ylabel('Standard Deviation BOLD Signal →')\n",
        "plt.title('BOLD Signals Standard Deviation for Different Genres')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F17G2RPev_LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['Rocknroll', 'Symphonic', 'Rocknroll', 'Metal', 'Symphonic', 'Country', 'Country', 'Ambient',\n",
        "          'Ambient', 'Country', 'Symphonic', 'Symphonic', 'Ambient', 'Metal', 'Metal', 'Ambient',\n",
        "          'Rocknroll', 'Country', 'Rocknroll', 'Ambient', 'Symphonic', 'Metal', 'Country', 'Metal',\n",
        "          'Rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create an empty array to accumulate BOLD signals for each genre\n",
        "all_bold_signals = []\n",
        "\n",
        "# Iterate over the dataframe and extract BOLD signals for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to volume number based on your logic\n",
        "    volume_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Ensure that volume_start is within bounds\n",
        "    volume_start = max(0, min(volume_start, nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Extract BOLD signals for each volume in the duration\n",
        "    bold_signals = nifti_data[:, :, :, volume_start:volume_start + 25].max(axis=(0, 1, 2))\n",
        "\n",
        "    # Accumulate the BOLD signals for each genre\n",
        "    all_bold_signals.append((genre, bold_signals))\n",
        "\n",
        "# Plot all BOLD signals in a single plot with different markers and line styles\n",
        "markers = ['o', 's', '^', 'D', '*', '2']\n",
        "line_styles = ['-', '-', '-', '-', '-', ':']\n",
        "for i, (genre, bold_signals) in enumerate(all_bold_signals):\n",
        "    plt.plot(bold_signals, label=genre, marker=markers[i % len(markers)], linestyle=line_styles[i % len(line_styles)])\n",
        "\n",
        "plt.xlabel('Time (Volumes) →')\n",
        "plt.ylabel('Maximum BOLD Signal →')\n",
        "plt.title('BOLD Signals Maximum for Different Genres')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NeWssAQov_Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['Rocknroll', 'Symphonic', 'Rocknroll', 'Metal', 'Symphonic', 'Country', 'Country', 'Ambient',\n",
        "          'Ambient', 'Country', 'Symphonic', 'Symphonic', 'Ambient', 'Metal', 'Metal', 'Ambient',\n",
        "          'Rocknroll', 'Country', 'Rocknroll', 'Ambient', 'Symphonic', 'Metal', 'Country', 'Metal',\n",
        "          'Rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create an empty array to accumulate BOLD signals for each genre\n",
        "all_bold_signals = []\n",
        "\n",
        "# Iterate over the dataframe and extract BOLD signals for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to volume number based on your logic\n",
        "    volume_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Ensure that volume_start is within bounds\n",
        "    volume_start = max(0, min(volume_start, nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Extract BOLD signals for each volume in the duration\n",
        "    bold_signals = np.median(nifti_data[:, :, :, volume_start:volume_start + 25], axis=(0, 1, 2))\n",
        "\n",
        "    # Accumulate the BOLD signals for each genre\n",
        "    all_bold_signals.append((genre, bold_signals))\n",
        "\n",
        "# Plot all BOLD signals in a single plot with different markers and line styles\n",
        "markers = ['o', 's', '^', 'D', '*', '2']\n",
        "line_styles = ['-', '-', '-', '-', '-', ':']\n",
        "for i, (genre, bold_signals) in enumerate(all_bold_signals):\n",
        "    plt.plot(bold_signals, label=genre, marker=markers[i % len(markers)], linestyle=line_styles[i % len(line_styles)])\n",
        "\n",
        "plt.xlabel('Time (Volumes) →')\n",
        "plt.ylabel('Median BOLD Signal →')\n",
        "plt.title('BOLD Signals Median for Different Genres')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "j-uEG1Idv_P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONNECTIVITY MATRIX**"
      ],
      "metadata": {
        "id": "bddpM4xZwWU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data:\n",
        "data = {\n",
        "    'onset': [0.01, 12, 24, 36, 48.01, 62, 74, 86, 98.01, 112, 122, 134, 144, 156, 166, 178, 190.02, 204, 216, 226, 236, 248.01, 262.01, 276, 288],\n",
        "    'duration': [6] * 25,\n",
        "    'genre': ['Rocknroll', 'Symphonic', 'Rocknroll', 'Metal', 'Symphonic', 'Country', 'Country', 'Ambient',\n",
        "          'Ambient', 'Country', 'Symphonic', 'Symphonic', 'Ambient', 'Metal', 'Metal', 'Ambient',\n",
        "          'Rocknroll', 'Country', 'Rocknroll', 'Ambient', 'Symphonic', 'Metal', 'Country', 'Metal',\n",
        "          'Rocknroll'],\n",
        "    'trigger_ts': [1233.5005, 1245.4996, 1257.4997, 1269.5, 1281.5003, 1295.4996, 1307.4993, 1319.4994,\n",
        "                   1331.499, 1345.4985, 1355.499, 1367.4987, 1377.4986, 1389.4985, 1399.4991, 1411.4989,\n",
        "                   1423.4995, 1437.4986, 1449.4994, 1459.4995, 1469.4986, 1481.4986, 1495.4987, 1509.4989,\n",
        "                   1521.4994]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the path to your 4D NIfTI file\n",
        "nifti_file_path = 'D:/MRI Dataset/ds00113b/sub-01/func/sub-01_task-auditoryperception_run-01_bold.nii.gz'\n",
        "\n",
        "# Load the NIfTI file\n",
        "nifti_image = nib.load(nifti_file_path)\n",
        "\n",
        "# Extract the data array\n",
        "nifti_data = nifti_image.get_fdata()\n",
        "\n",
        "# Create a subfolder for displaying connectivity matrices\n",
        "display_folder = 'display_matrices'\n",
        "os.makedirs(display_folder, exist_ok=True)\n",
        "\n",
        "# Iterate over the dataframe and extract BOLD signals for each genre\n",
        "for index, row in df.iterrows():\n",
        "    genre = row['genre']\n",
        "    onset = row['onset']\n",
        "    duration = row['duration']\n",
        "    timestamp = row['trigger_ts']\n",
        "\n",
        "    # Convert timestamp to volume number based on your logic\n",
        "    volume_start = int((timestamp - df['trigger_ts'].min()) / (df['trigger_ts'].max() - df['trigger_ts'].min()) * (nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Ensure that volume_start is within bounds\n",
        "    volume_start = max(0, min(volume_start, nifti_data.shape[3] - 25))\n",
        "\n",
        "    # Extract BOLD signals for each volume in the duration\n",
        "    bold_signals = nifti_data[:, :, :, volume_start:volume_start + 25]\n",
        "\n",
        "    # Select a random voxel as the center of the ROI\n",
        "    center_voxel = np.random.randint(0, bold_signals.shape[0]), np.random.randint(0, bold_signals.shape[1]), np.random.randint(0, bold_signals.shape[2])\n",
        "\n",
        "    # Define the size of the ROI\n",
        "    roi_size = 5\n",
        "\n",
        "    # Extract the ROI\n",
        "    roi = bold_signals[\n",
        "        max(0, center_voxel[0] - roi_size): min(bold_signals.shape[0], center_voxel[0] + roi_size + 1),\n",
        "        max(0, center_voxel[1] - roi_size): min(bold_signals.shape[1], center_voxel[1] + roi_size + 1),\n",
        "        max(0, center_voxel[2] - roi_size): min(bold_signals.shape[2], center_voxel[2] + roi_size + 1),\n",
        "        :\n",
        "    ]\n",
        "\n",
        "    # Reshape the signals for correlation calculation\n",
        "    reshaped_signals = roi.reshape(-1, roi.shape[-1])\n",
        "\n",
        "    # Compute the correlation matrix\n",
        "    correlation_matrix = np.corrcoef(reshaped_signals)\n",
        "\n",
        "    # Display a heatmap of the correlation matrix with color bar range 0 to 1\n",
        "    plt.imshow(correlation_matrix, cmap='viridis', vmin=0, vmax=1)\n",
        "    plt.colorbar()\n",
        "    plt.title(f'{genre}')\n",
        "    plt.xlabel('Source Voxels')\n",
        "    plt.ylabel('Target Voxels')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WZG_QjQNv_R8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}